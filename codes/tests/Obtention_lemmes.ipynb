{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce7b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433d148a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.16 (default, Jan 17 2023, 22:20:44) \\n[GCC 11.2.0]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a2bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/noe/Documents/2022-2023/ENC/Mémoire/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1384a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Dataframe_PDV_Vers_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea47f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# specify the file name and format\n",
    "filename = \"test.csv\"\n",
    "file_format = \"csv\"\n",
    "colnames = 'lemmes'\n",
    "# specify the encoding of the file (e.g., utf-8, latin-1, etc.)\n",
    "file_encoding = \"utf-8\"\n",
    "\n",
    "# read the file using pandas with the specified format and encoding\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a60df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noe = list(df['lemma'])\n",
    "final = ' '.join(noe)\n",
    "with open('texte_21.txt','w') as file:\n",
    "    file.write(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c9d2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Livre</th>\n",
       "      <th>Numéro de la charte</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Date</th>\n",
       "      <th>Textes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Livre 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Querimonia Friderici imperatoris, super deposi...</td>\n",
       "      <td>1240</td>\n",
       "      <td>1. Collegerunt pontifices et Pharisei consiliu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Livre 1</td>\n",
       "      <td>2</td>\n",
       "      <td>Fridericus regibus et principibus mundi, ut no...</td>\n",
       "      <td>1246</td>\n",
       "      <td>1. Illos felices describit antiquitas, quibus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Livre 1</td>\n",
       "      <td>3</td>\n",
       "      <td>Fridericus Regi Franciae, super sententia depo...</td>\n",
       "      <td>1245</td>\n",
       "      <td>1. Etsi causae nostrae iustitiam, uulgaris fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Livre 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Fridericus magistro iustitiario regni Syciliae...</td>\n",
       "      <td>1247</td>\n",
       "      <td>1. Ne per excogitatae malignitatis astutiam is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Livre 1</td>\n",
       "      <td>5</td>\n",
       "      <td>Fridericus regi Franciae significat aliqua fac...</td>\n",
       "      <td>1243</td>\n",
       "      <td>1. Virum industrium et illustrem R., comitem T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>Livre 6</td>\n",
       "      <td>28</td>\n",
       "      <td>De eodem</td>\n",
       "      <td>1220-1266</td>\n",
       "      <td>1. Fauorabilis petitio supplicantium effectu d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>Livre 6</td>\n",
       "      <td>29</td>\n",
       "      <td>Recipit in gratiam suam quemdam, remittendo ei...</td>\n",
       "      <td>1238-1239</td>\n",
       "      <td>1. Tenore presentium notum facimus uniuersis, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>Livre 6</td>\n",
       "      <td>30</td>\n",
       "      <td>Priuilegium concessum libertatis quibusdam gen...</td>\n",
       "      <td>1224</td>\n",
       "      <td>1, Ad hoc summi dispensatione consilii princip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>Livre 6</td>\n",
       "      <td>31</td>\n",
       "      <td>Exordium super gratiis faciendis conuersis nov...</td>\n",
       "      <td>1240</td>\n",
       "      <td>1. Consueuit innata benignitas, consuetudo reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>Livre 6</td>\n",
       "      <td>32</td>\n",
       "      <td>Concessio officii notariatus</td>\n",
       "      <td>1231-1250</td>\n",
       "      <td>1. Notum facimus uniuersitati uestrae, quod .....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    Livre  Numéro de la charte  \\\n",
       "0             0  Livre 1                    1   \n",
       "1             1  Livre 1                    2   \n",
       "2             2  Livre 1                    3   \n",
       "3             3  Livre 1                    4   \n",
       "4             4  Livre 1                    5   \n",
       "..          ...      ...                  ...   \n",
       "358         358  Livre 6                   28   \n",
       "359         359  Livre 6                   29   \n",
       "360         360  Livre 6                   30   \n",
       "361         361  Livre 6                   31   \n",
       "362         362  Livre 6                   32   \n",
       "\n",
       "                                                 Titre       Date  \\\n",
       "0    Querimonia Friderici imperatoris, super deposi...       1240   \n",
       "1    Fridericus regibus et principibus mundi, ut no...       1246   \n",
       "2    Fridericus Regi Franciae, super sententia depo...       1245   \n",
       "3    Fridericus magistro iustitiario regni Syciliae...       1247   \n",
       "4    Fridericus regi Franciae significat aliqua fac...       1243   \n",
       "..                                                 ...        ...   \n",
       "358                                           De eodem  1220-1266   \n",
       "359  Recipit in gratiam suam quemdam, remittendo ei...  1238-1239   \n",
       "360  Priuilegium concessum libertatis quibusdam gen...       1224   \n",
       "361  Exordium super gratiis faciendis conuersis nov...       1240   \n",
       "362                       Concessio officii notariatus  1231-1250   \n",
       "\n",
       "                                                Textes  \n",
       "0    1. Collegerunt pontifices et Pharisei consiliu...  \n",
       "1    1. Illos felices describit antiquitas, quibus ...  \n",
       "2    1. Etsi causae nostrae iustitiam, uulgaris fam...  \n",
       "3    1. Ne per excogitatae malignitatis astutiam is...  \n",
       "4    1. Virum industrium et illustrem R., comitem T...  \n",
       "..                                                 ...  \n",
       "358  1. Fauorabilis petitio supplicantium effectu d...  \n",
       "359  1. Tenore presentium notum facimus uniuersis, ...  \n",
       "360  1, Ad hoc summi dispensatione consilii princip...  \n",
       "361  1. Consueuit innata benignitas, consuetudo reg...  \n",
       "362  1. Notum facimus uniuersitati uestrae, quod .....  \n",
       "\n",
       "[363 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ceb5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    first = re.sub(\"\\n\",\"\",string)\n",
    "    new_string = re.sub(\"[0-9]. \",'',first)\n",
    "    new_string_2 = re.sub('- ','',new_string)\n",
    "    final = re.sub(' . ',' ', new_string_2)\n",
    "    final2 = re.sub('-, ','',final)\n",
    "    final3 = re.sub('[0-9]','',final2)\n",
    "    return final3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93ec833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textes'] = df['Textes'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7404b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Livre','Numéro de la charte','Titre','Date','textes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3db314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: HEAD n'est pas un nom d'objet valide\n"
     ]
    }
   ],
   "source": [
    "df[\"textes\"] = df[\"textes\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "\n",
    "from typing import List\n",
    "from pie_extended.cli.utils import get_tagger, get_model, download\n",
    "\n",
    "# In case you need to download\n",
    "do_download = False\n",
    "if do_download:\n",
    "    for dl in download(\"lasla\"):\n",
    "        x = 1\n",
    "\n",
    "# model_path allows you to override the model loaded by another .tar\n",
    "model_name = \"lasla\"\n",
    "tagger = get_tagger(model_name, batch_size=256, device=\"cpu\", model_path=None)\n",
    "\n",
    "\n",
    "\n",
    "i = 24\n",
    "\n",
    "while i<=362:   \n",
    "    liste_lemmes = []\n",
    "    sentences: List[str] = [df['textes'][i]]\n",
    "    # Get the main object from the model (: data iterator + postprocesor\n",
    "    from pie_extended.models.lasla.imports import get_iterator_and_processor\n",
    "    for sentence_group in sentences:\n",
    "        iterator, processor = get_iterator_and_processor()\n",
    "        dic = tagger.tag_str(sentence_group, iterator=iterator, processor=processor)\n",
    "\n",
    "    for elm in dic:\n",
    "        if elm['pos'] == 'ADJqua' or elm['pos'] == 'VER' or elm['pos'] == 'NOMcom' or elm['pos'] == 'NOMpro' or elm['pos'] == 'ADJcar' or elm['pos'] == 'ADJord' or elm['pos'] == 'ADJmul' or elm['pos'] == 'ADJdis':\n",
    "            liste_lemmes.append(elm['lemma'])\n",
    "    texte = ' '.join(liste_lemmes)\n",
    "\n",
    "    with open(f'texte_{i+1}.txt','w') as file:\n",
    "        file.write(texte)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0c757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/noe/Documents/2022-2023/ENC/Mémoire/Livres_OCR_par_chartes/Livre_1/Texte_fin/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e94a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_21.txt','r') as file:\n",
    "    data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe64047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    i = i.replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04ed0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data =[element.rstrip() for element in data]\n",
    "haha = ' '.join(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa483675",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean_text(haha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb626971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: HEAD n'est pas un nom d'objet valide\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pie_extended.cli.utils import get_tagger, get_model, download\n",
    "\n",
    "# In case you need to download\n",
    "do_download = False\n",
    "if do_download:\n",
    "    for dl in download(\"lasla\"):\n",
    "        x = 1\n",
    "\n",
    "# model_path allows you to override the model loaded by another .tar\n",
    "model_name = \"lasla\"\n",
    "tagger = get_tagger(model_name, batch_size=256, device=\"cpu\", model_path=None)\n",
    "\n",
    "\n",
    "i = 20\n",
    "    \n",
    "liste_lemmes = []\n",
    "sentences: List[str] = [clean]\n",
    "# Get the main object from the model (: data iterator + postprocesor\n",
    "from pie_extended.models.lasla.imports import get_iterator_and_processor\n",
    "for sentence_group in sentences:\n",
    "    iterator, processor = get_iterator_and_processor()\n",
    "    dic = tagger.tag_str(sentence_group, iterator=iterator, processor=processor)\n",
    "\n",
    "for elm in dic:\n",
    "    if elm['pos'] == 'ADJqua' or elm['pos'] == 'VER' or elm['pos'] == 'NOMcom' or elm['pos'] == 'NOMpro' or elm['pos'] == 'ADJcar' or elm['pos'] == 'ADJord' or elm['pos'] == 'ADJmul' or elm['pos'] == 'ADJdis':\n",
    "        liste_lemmes.append(elm['lemma'])\n",
    "texte = ' '.join(liste_lemmes)\n",
    "\n",
    "with open(f'texte_{i+1}.txt','w') as file:\n",
    "    file.write(texte)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da282420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = '/home/noe/Documents/2022-2023/ENC/Mémoire/Livres_OCR_par_chartes/lemmas/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25bff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['texte_137.txt',\n",
       " 'texte_147.txt',\n",
       " 'texte_189.txt',\n",
       " 'texte_268.txt',\n",
       " 'texte_222.txt',\n",
       " 'texte_130.txt',\n",
       " 'texte_170.txt',\n",
       " 'texte_111.txt',\n",
       " 'texte_120.txt',\n",
       " 'texte_209.txt',\n",
       " 'texte_34.txt',\n",
       " 'texte_126.txt',\n",
       " 'texte_328.txt',\n",
       " 'texte_265.txt',\n",
       " 'texte_194.txt',\n",
       " 'texte_141.txt',\n",
       " 'texte_320.txt',\n",
       " 'texte_3.txt',\n",
       " 'texte_36.txt',\n",
       " 'texte_75.txt',\n",
       " 'texte_59.txt',\n",
       " 'texte_229.txt',\n",
       " 'texte_116.txt',\n",
       " 'texte_83.txt',\n",
       " 'texte_132.txt',\n",
       " 'texte_308.txt',\n",
       " 'texte_197.txt',\n",
       " 'texte_312.txt',\n",
       " 'texte_283.txt',\n",
       " 'texte_42.txt',\n",
       " 'texte_168.txt',\n",
       " 'texte_356.txt',\n",
       " 'texte_175.txt',\n",
       " 'texte_172.txt',\n",
       " 'texte_349.txt',\n",
       " 'texte_78.txt',\n",
       " 'texte_65.txt',\n",
       " 'texte_122.txt',\n",
       " 'texte_324.txt',\n",
       " 'texte_38.txt',\n",
       " 'texte_153.txt',\n",
       " 'texte_304.txt',\n",
       " 'texte_96.txt',\n",
       " 'texte_325.txt',\n",
       " 'texte_113.txt',\n",
       " 'texte_10.txt',\n",
       " 'texte_334.txt',\n",
       " 'texte_145.txt',\n",
       " 'texte_174.txt',\n",
       " 'texte_179.txt',\n",
       " 'texte_127.txt',\n",
       " 'texte_358.txt',\n",
       " 'texte_354.txt',\n",
       " 'texte_82.txt',\n",
       " 'texte_138.txt',\n",
       " 'texte_338.txt',\n",
       " 'texte_302.txt',\n",
       " 'texte_262.txt',\n",
       " 'texte_158.txt',\n",
       " 'texte_264.txt',\n",
       " 'texte_336.txt',\n",
       " 'texte_252.txt',\n",
       " 'texte_88.txt',\n",
       " 'texte_173.txt',\n",
       " 'texte_299.txt',\n",
       " 'texte_91.txt',\n",
       " 'texte_269.txt',\n",
       " 'texte_310.txt',\n",
       " 'texte_290.txt',\n",
       " 'texte_353.txt',\n",
       " 'texte_291.txt',\n",
       " 'texte_163.txt',\n",
       " 'texte_139.txt',\n",
       " 'texte_18.txt',\n",
       " 'texte_154.txt',\n",
       " 'texte_231.txt',\n",
       " 'texte_332.txt',\n",
       " 'texte_118.txt',\n",
       " 'texte_206.txt',\n",
       " 'texte_41.txt',\n",
       " 'texte_250.txt',\n",
       " 'texte_203.txt',\n",
       " 'texte_235.txt',\n",
       " 'texte_221.txt',\n",
       " 'texte_156.txt',\n",
       " 'texte_228.txt',\n",
       " 'texte_309.txt',\n",
       " 'texte_164.txt',\n",
       " 'texte_281.txt',\n",
       " 'texte_298.txt',\n",
       " 'texte_47.txt',\n",
       " 'texte_45.txt',\n",
       " 'texte_350.txt',\n",
       " 'texte_2.txt',\n",
       " 'texte_272.txt',\n",
       " 'texte_52.txt',\n",
       " 'texte_275.txt',\n",
       " 'texte_256.txt',\n",
       " 'texte_63.txt',\n",
       " 'texte_176.txt',\n",
       " 'texte_40.txt',\n",
       " 'texte_166.txt',\n",
       " 'texte_89.txt',\n",
       " 'texte_124.txt',\n",
       " 'texte_213.txt',\n",
       " 'texte_159.txt',\n",
       " 'texte_198.txt',\n",
       " 'texte_48.txt',\n",
       " 'texte_345.txt',\n",
       " 'texte_335.txt',\n",
       " 'texte_261.txt',\n",
       " 'texte_227.txt',\n",
       " 'texte_98.txt',\n",
       " 'texte_188.txt',\n",
       " 'texte_294.txt',\n",
       " 'texte_31.txt',\n",
       " 'texte_273.txt',\n",
       " 'texte_243.txt',\n",
       " 'texte_30.txt',\n",
       " 'texte_293.txt',\n",
       " 'texte_131.txt',\n",
       " 'texte_348.txt',\n",
       " 'texte_186.txt',\n",
       " 'texte_99.txt',\n",
       " 'texte_16.txt',\n",
       " 'texte_342.txt',\n",
       " 'texte_129.txt',\n",
       " 'texte_295.txt',\n",
       " 'texte_284.txt',\n",
       " 'texte_177.txt',\n",
       " 'texte_19.txt',\n",
       " 'texte_151.txt',\n",
       " 'texte_134.txt',\n",
       " 'texte_50.txt',\n",
       " 'texte_180.txt',\n",
       " 'texte_204.txt',\n",
       " 'texte_146.txt',\n",
       " 'texte_351.txt',\n",
       " 'texte_190.txt',\n",
       " 'texte_341.txt',\n",
       " 'texte_311.txt',\n",
       " 'texte_219.txt',\n",
       " 'texte_249.txt',\n",
       " 'texte_26.txt',\n",
       " 'texte_317.txt',\n",
       " 'texte_306.txt',\n",
       " 'texte_286.txt',\n",
       " 'texte_330.txt',\n",
       " 'texte_199.txt',\n",
       " 'texte_22.txt',\n",
       " 'texte_109.txt',\n",
       " 'texte_223.txt',\n",
       " 'texte_102.txt',\n",
       " 'texte_71.txt',\n",
       " 'texte_278.txt',\n",
       " 'texte_23.txt',\n",
       " 'texte_337.txt',\n",
       " 'texte_248.txt',\n",
       " 'texte_8.txt',\n",
       " 'texte_117.txt',\n",
       " 'texte_68.txt',\n",
       " 'texte_259.txt',\n",
       " 'texte_214.txt',\n",
       " 'texte_316.txt',\n",
       " 'texte_263.txt',\n",
       " 'texte_74.txt',\n",
       " 'texte_192.txt',\n",
       " 'texte_240.txt',\n",
       " 'texte_73.txt',\n",
       " 'texte_271.txt',\n",
       " 'texte_331.txt',\n",
       " 'texte_355.txt',\n",
       " 'texte_169.txt',\n",
       " 'texte_200.txt',\n",
       " 'texte_144.txt',\n",
       " 'texte_303.txt',\n",
       " 'texte_14.txt',\n",
       " 'texte_360.txt',\n",
       " 'texte_315.txt',\n",
       " 'texte_329.txt',\n",
       " 'texte_191.txt',\n",
       " 'texte_346.txt',\n",
       " 'texte_51.txt',\n",
       " 'texte_29.txt',\n",
       " 'texte_56.txt',\n",
       " 'texte_140.txt',\n",
       " 'texte_319.txt',\n",
       " 'texte_253.txt',\n",
       " 'texte_54.txt',\n",
       " 'texte_72.txt',\n",
       " 'texte_58.txt',\n",
       " 'texte_260.txt',\n",
       " 'texte_103.txt',\n",
       " 'texte_292.txt',\n",
       " 'texte_251.txt',\n",
       " 'texte_201.txt',\n",
       " 'texte_160.txt',\n",
       " 'texte_247.txt',\n",
       " 'texte_119.txt',\n",
       " 'texte_161.txt',\n",
       " 'texte_70.txt',\n",
       " 'texte_215.txt',\n",
       " 'texte_185.txt',\n",
       " 'texte_39.txt',\n",
       " 'texte_110.txt',\n",
       " 'texte_182.txt',\n",
       " 'texte_21.txt',\n",
       " 'texte_258.txt',\n",
       " 'texte_257.txt',\n",
       " 'texte_87.txt',\n",
       " 'texte_69.txt',\n",
       " 'texte_64.txt',\n",
       " 'texte_149.txt',\n",
       " 'texte_76.txt',\n",
       " 'texte_15.txt',\n",
       " 'texte_106.txt',\n",
       " 'texte_167.txt',\n",
       " 'texte_162.txt',\n",
       " 'texte_333.txt',\n",
       " 'texte_236.txt',\n",
       " 'texte_285.txt',\n",
       " 'texte_9.txt',\n",
       " 'texte_326.txt',\n",
       " 'texte_224.txt',\n",
       " 'texte_318.txt',\n",
       " 'texte_276.txt',\n",
       " 'texte_280.txt',\n",
       " 'texte_193.txt',\n",
       " 'texte_121.txt',\n",
       " 'texte_339.txt',\n",
       " 'texte_212.txt',\n",
       " 'texte_79.txt',\n",
       " 'texte_28.txt',\n",
       " 'texte_57.txt',\n",
       " 'texte_296.txt',\n",
       " 'texte_178.txt',\n",
       " 'texte_362.txt',\n",
       " 'texte_234.txt',\n",
       " 'texte_220.txt',\n",
       " 'texte_288.txt',\n",
       " 'texte_128.txt',\n",
       " 'texte_1.txt',\n",
       " 'texte_196.txt',\n",
       " 'texte_361.txt',\n",
       " 'texte_24.txt',\n",
       " 'texte_187.txt',\n",
       " 'texte_218.txt',\n",
       " 'texte_94.txt',\n",
       " 'texte_107.txt',\n",
       " 'texte_93.txt',\n",
       " 'texte_62.txt',\n",
       " 'texte_112.txt',\n",
       " 'texte_287.txt',\n",
       " 'texte_85.txt',\n",
       " 'texte_245.txt',\n",
       " 'texte_344.txt',\n",
       " 'texte_274.txt',\n",
       " 'texte_104.txt',\n",
       " 'texte_300.txt',\n",
       " 'texte_143.txt',\n",
       " 'texte_114.txt',\n",
       " 'texte_4.txt',\n",
       " 'texte_6.txt',\n",
       " 'texte_232.txt',\n",
       " 'texte_123.txt',\n",
       " 'texte_202.txt',\n",
       " 'texte_133.txt',\n",
       " 'texte_80.txt',\n",
       " 'texte_37.txt',\n",
       " 'texte_60.txt',\n",
       " 'texte_97.txt',\n",
       " 'texte_255.txt',\n",
       " 'texte_237.txt',\n",
       " 'texte_136.txt',\n",
       " 'texte_152.txt',\n",
       " 'texte_267.txt',\n",
       " 'texte_233.txt',\n",
       " 'texte_44.txt',\n",
       " 'texte_101.txt',\n",
       " 'texte_100.txt',\n",
       " 'texte_49.txt',\n",
       " 'texte_46.txt',\n",
       " 'texte_53.txt',\n",
       " 'texte_148.txt',\n",
       " 'texte_226.txt',\n",
       " 'texte_25.txt',\n",
       " 'texte_205.txt',\n",
       " 'texte_340.txt',\n",
       " 'texte_66.txt',\n",
       " 'texte_321.txt',\n",
       " 'texte_301.txt',\n",
       " 'texte_347.txt',\n",
       " 'texte_108.txt',\n",
       " 'texte_13.txt',\n",
       " 'texte_279.txt',\n",
       " 'texte_61.txt',\n",
       " 'texte_17.txt',\n",
       " 'texte_105.txt',\n",
       " 'texte_92.txt',\n",
       " 'texte_305.txt',\n",
       " 'texte_343.txt',\n",
       " 'texte_210.txt',\n",
       " 'texte_277.txt',\n",
       " 'texte_95.txt',\n",
       " 'texte_313.txt',\n",
       " 'texte_208.txt',\n",
       " 'texte_27.txt',\n",
       " 'texte_242.txt',\n",
       " 'texte_254.txt',\n",
       " 'texte_359.txt',\n",
       " 'texte_155.txt',\n",
       " 'texte_289.txt',\n",
       " 'texte_67.txt',\n",
       " 'texte_115.txt',\n",
       " 'texte_195.txt',\n",
       " 'texte_297.txt',\n",
       " 'texte_184.txt',\n",
       " 'texte_183.txt',\n",
       " 'texte_12.txt',\n",
       " 'texte_7.txt',\n",
       " 'texte_352.txt',\n",
       " 'texte_322.txt',\n",
       " 'texte_55.txt',\n",
       " 'texte_225.txt',\n",
       " 'texte_142.txt',\n",
       " 'texte_35.txt',\n",
       " 'texte_241.txt',\n",
       " 'texte_239.txt',\n",
       " 'texte_135.txt',\n",
       " 'texte_307.txt',\n",
       " 'texte_171.txt',\n",
       " 'texte_165.txt',\n",
       " 'texte_327.txt',\n",
       " 'texte_11.txt',\n",
       " 'texte_43.txt',\n",
       " 'texte_157.txt',\n",
       " 'texte_238.txt',\n",
       " 'texte_357.txt',\n",
       " 'texte_5.txt',\n",
       " 'texte_20.txt',\n",
       " 'texte_230.txt',\n",
       " 'texte_266.txt',\n",
       " 'texte_86.txt',\n",
       " 'texte_282.txt',\n",
       " 'texte_125.txt',\n",
       " 'texte_207.txt',\n",
       " 'texte_84.txt',\n",
       " 'texte_32.txt',\n",
       " 'texte_181.txt',\n",
       " 'texte_270.txt',\n",
       " 'texte_217.txt',\n",
       " 'texte_323.txt',\n",
       " 'texte_314.txt',\n",
       " 'texte_81.txt',\n",
       " 'texte_244.txt',\n",
       " 'texte_246.txt',\n",
       " 'texte_216.txt',\n",
       " 'texte_33.txt',\n",
       " 'texte_211.txt',\n",
       " 'texte_150.txt',\n",
       " 'texte_77.txt',\n",
       " 'texte_90.txt',\n",
       " 'texte_363.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_textes = os.listdir(path)\n",
    "liste_textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab501746",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lemmas = []\n",
    "\n",
    "while i <= 362:\n",
    "    with open(f'texte_{i+1}.txt','r') as file:\n",
    "        data = file.readlines()\n",
    "    lemmas.extend(data)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b18530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'] = lemmas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
