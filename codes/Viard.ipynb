{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da6270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib.patches import Polygon\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05f7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/noe/Documents/2022-2023/ENC/Mémoire/Viard/Viard.xml'\n",
    "viard = '/home/noe/Documents/2022-2023/ENC/Mémoire/Viard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8abde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#création d'un xml avec juste les textes sans l'apparat\n",
    "with open(path,'r') as file:\n",
    "    data = file.read()\n",
    "soup = BeautifulSoup(data,'xml')\n",
    "tag = soup.find('group')\n",
    "new_soup = BeautifulSoup(features='xml')\n",
    "new_soup.append(tag)\n",
    "with open('group.xml', 'w') as f:\n",
    "    f.write(new_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c82e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = 'notum facimus'\n",
    "element_2 = 'Notum facimus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ca0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(viard+'group.xml','r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961e0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#création des fichiers pour chaque texte\n",
    "soup = BeautifulSoup(data,'xml')\n",
    "text_tags = soup.find_all('text')\n",
    "for i, tag in enumerate(text_tags):\n",
    "    new_soup = BeautifulSoup(features='xml')\n",
    "    new_soup.append(tag)\n",
    "    with open(f'text_{i}.xml', 'w') as f:\n",
    "        f.write(new_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107bddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/noe/Documents/2022-2023/ENC/Mémoire/Viard/textes/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c58cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "dic = {}\n",
    "\n",
    "while i <= 443:\n",
    "    \n",
    "    with open(f'text_{i}.xml','r') as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    latin = []\n",
    "    key_name = []\n",
    "    \n",
    "    if element in data or element_2 in data:\n",
    "        \n",
    "        soup = BeautifulSoup(data,'xml')\n",
    "        for tag in soup.find_all(final):\n",
    "            tag.decompose()\n",
    "        \n",
    "        body_tag = soup.find('body')\n",
    "        body_text = body_tag.text.strip()\n",
    "        latin.append(body_text)\n",
    "        key_name.append(f'text_{i+1}')\n",
    "\n",
    "    dic.update({str(key_name):latin})\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730b5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of tags\n",
    "\n",
    "i = 0\n",
    "\n",
    "liste_tags = []\n",
    "\n",
    "while i <=443:\n",
    "    \n",
    "    with open(f'text_{i}.xml','r') as file:\n",
    "        data = file.read()\n",
    "        \n",
    "    if element in data or element_2 in data:\n",
    "        soup=BeautifulSoup(data,'xml')\n",
    "        parent = soup.find('body')\n",
    "        tag_list = [tag.name for tag in parent.find_all()]\n",
    "        liste_tags.extend(tag_list)\n",
    "        \n",
    "    i += 1\n",
    "#cration of final list\n",
    "final = list(set(liste_tags))\n",
    "\n",
    "final.remove('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "433d9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_remove = []\n",
    "\n",
    "for key, value in dic.items():\n",
    "    if value == []:\n",
    "        keys_to_remove.append(key)\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    del dic[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7e58f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['id','text']\n",
    "df = pd.DataFrame(dic.items())\n",
    "df.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54beaef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    s = s.replace(\"['\", \"\")\n",
    "    s = s.replace(\"']\", \"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd4e483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['id'].apply(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f0e0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a93547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    first = re.sub(\"\\n\",\"\",string)\n",
    "    new_string = re.sub(\"[0-9]. \",'',first)\n",
    "    new_string_2 = re.sub('- ','',new_string)\n",
    "    final = re.sub(' . ',' ', new_string_2)\n",
    "    final2 = re.sub('-, ','',final)\n",
    "    final3 = re.sub('[0-9]','',final2)\n",
    "    return final3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ed988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "933586e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b68cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd5766c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "65",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/python/miniconda/envs/coursnlp/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 65 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36936/2960792086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mliste_lemmes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Get the main object from the model (: data iterator + postprocesor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpie_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlasla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_iterator_and_processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/miniconda/envs/coursnlp/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/miniconda/envs/coursnlp/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/miniconda/envs/coursnlp/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 65"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pie_extended.cli.utils import get_tagger, get_model, download\n",
    "\n",
    "# In case you need to download\n",
    "do_download = False\n",
    "if do_download:\n",
    "    for dl in download(\"lasla\"):\n",
    "        x = 1\n",
    "\n",
    "# model_path allows you to override the model loaded by another .tar\n",
    "model_name = \"lasla\"\n",
    "tagger = get_tagger(model_name, batch_size=256, device=\"cpu\", model_path=None)\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "while i <= 64:\n",
    "    \n",
    "    liste_lemmes = []\n",
    "    \n",
    "    sentences: List[str] = [df['text'][i]]\n",
    "    # Get the main object from the model (: data iterator + postprocesor\n",
    "    from pie_extended.models.lasla.imports import get_iterator_and_processor\n",
    "    for sentence_group in sentences:\n",
    "        iterator, processor = get_iterator_and_processor()\n",
    "        lemma = tagger.tag_str(sentence_group, iterator=iterator, processor=processor) \n",
    "\n",
    "    for elm in lemma:\n",
    "        if elm['pos'] == 'ADJqua' or elm['pos'] == 'VER' or elm['pos'] == 'NOMcom' or elm['pos'] == 'NOMpro' or elm['pos'] == 'ADJcar' or elm['pos'] == 'ADJord' or elm['pos'] == 'ADJmul' or elm['pos'] == 'ADJdis':\n",
    "            liste_lemmes.append(elm['lemma'])\n",
    "    texte = ' '.join(liste_lemmes)\n",
    "    \n",
    "    with open(f'texte_{i+1}.txt','w') as file:\n",
    "        file.write(texte)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d437800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lemmas = []\n",
    "\n",
    "while i < 65:\n",
    "    with open(f'texte_{i+1}.txt','r') as file:\n",
    "        data = file.readlines()\n",
    "    lemmas.extend(data)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9082bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc163e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Philippus, Valesii et Andegavie comes, Francie et Navarre regna regens, notum facimus universis presentibus et futuris quod cum Stephanus le Haubergier, civis Parisiensis, quoddam nobile feodum valoris duodecim librarum parisiensium annui redditus, vel circa, situm in villa de Antogniaco et eius territorio, quod religioso viro, abbate Sancti Germani de Pratis prope Parisius tenetur per homagium, certo et legitimo titulo, sicut asserit, duxerit acquirendum; prefatus tamen abbas, eumdem Stephanum, eo quod nobilis non existit, in suum recipere homagium pro memorato feodo recusavit et adhuc recu sat; unde, nobis, prefatus Stephanus humiliter supplicavit ut super hoc sibi specialem gratiam facere dignaremur. Nos igitur, ejusdem in hac parte supplicationibus favorabiliter annuentes, eidem Stephano, de speciali gratia concedimus, pro se et heredibus suis, ut ipse et ipsius heredes, licet idem Stephanus, a nobilibus originem non traxerit, dictum feodum, ac si esset nobilis tenere possint imperpetuum pacifice et quiete; ipsumque Stephanum, auctoritate nostra habilitantes, quo ad hoc per présentes volentes et precipientes quod idem abbas eumdem Stephanum, ex nunc in suum pro dicto feodo recipiat homagium, impedimento predicto omnino cessante. Quod ut firmum et stabile permaneat in futurum, presentibus litteris, sigillum nostrum quo antequam dictorum regnorum ad nos deve nisset regimen utebamur, fecimus apponi. Actum Parisius, anno Domini millesimo CCCo vicesimo septimo, mense Januarii . Per dominum regentem, ad relationem dominorum Thome de Marfonte et Petri de Cuigneriis . J. de Templo.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
